---
title: "Untitled"
author: "RRiddell"
date: "06/08/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(corrr)
library(caret)
```

```{r eval=FALSE, include=FALSE}
source("funs/data_cleaner.R")
```

```{r}
all_data <- read_csv("out/all_data.csv")
game_total <- read_csv("out/game_total.csv")
```

```{r}
training <- game_total %>%  
  select(!country) %>% 
  filter(year != 2019)

testing <- game_total %>% 
  select(!country) %>% 
  filter(year == 2019)

testing_countries <- game_total %>% 
  filter(year == 2019) %>% 
  select(country)

```

```{r}
ggplot(training, aes(x = pts, y =..density..)) +
  geom_histogram(colour = 'violet', fill = 'violet', alpha = 0.8, binwidth = 10) +
  geom_density(fill = 'black', alpha = 0.3) +
  geom_vline(xintercept = mean(training$score_margin), linetype = "dashed", colour = "blue")
```


```{r}
cat_vars <- c("year", "tournament_stage", "competition", "results")

gg_box <- function(x){
  ggplot(game_total, aes(factor(.data[[x]]), pts)) +
  geom_boxplot()
}

for (i in cat_vars){
  print(gg_box(i))
}

```


```{r}
num_vars <- training %>% 
  select(mp:mean_PER, -results) %>% 
  colnames(.)

gg_point <- function(y){
  ggplot(training, aes(pts, .data[[y]])) +
  geom_point() +
    geom_text(x = max(training$pts) *.90, 
              y = max(training[[y]]) *.90, 
              aes(label = paste("R:",round(cor(training$pts, .data[[y]]),2))))
}

for (i in num_vars){
  print(gg_point(i))
}

```

```{r}
cor_mat <- training %>% 
  select(where(is.numeric),-pts) %>% 
  cor(., method = 'spearman')

## select the variables that display multicolinearty above 0.8
cor_features <- findCorrelation(cor_mat, cutoff = 0.8, names = T, exact = FALSE)

## remove the variables that display multicolinearty
## leaving the variables that best represent the correlation
training <- training %>% 
  select(-cor_features)

```

```{r}
ordered_colnames <- training %>% 
  select(where(is.numeric)) %>% 
  correlate() %>% 
  focus(pts) %>% 
  mutate(pts = abs(pts)) %>% 
  arrange(pts)

low_cor <- ordered_colnames %>% 
  filter(pts < .2) %>% 
  pull(term) 

training <- training %>% 
  select(!low_cor)
```


```{r}
training <- training %>% 
  select(!c(x3pa, x3P_p))

GGally::ggcorr(training, method = c('pairwise','spearman'), 
               size = 2 )

nearZeroVar(training, names = T)
e1071::skewness(training$pts)

Skewness <- training %>%
  select(where(is.numeric)) %>% 
  summarise(across(c(x3p:tsa),e1071::skewness)) %>% 
  gather(Variable, Skewness) %>% 
  arrange(-Skewness)
```

```{r}
dummy_obj <- dummyVars(pts ~ . , data = training)
training_withDummies <- predict(dummy_obj, newdata = training)
training_withDummies <- bind_cols(training_withDummies, pts = training$pts)
names(training_withDummies) <- str_replace_all(string = names(training_withDummies),
                                               pattern = " ", 
                                               replace= "_")
```

```{r}
control_obj <- trainControl(method = "cv", number = 5)

```

```{r}
library(MASS)
set.seed(1)
lm_mdl <- train(pts ~ . , data =  training, 
                method = 'lmStepAIC',
                trControl = control_obj,
                trace = F)

broom::tidy(lm_mdl$finalModel, confint=T)
lm_mdl
detach("package:MASS")
```

```{r}
set.seed(1)
colnames(training_withDummies) <- make.names(colnames(training_withDummies))
## running the random forest variable using the training with dummy variable
tree_mdl <- train(pts ~ . , data = training_withDummies,
                  method = 'rpart',
                  trControl = control_obj,
                  tuneGrid = expand.grid(cp = seq(0.001,0.015,0.001)))
## the regression tree had an average RMSE of ~40 and was able to explain ~16% of the variation in the model  
tree_mdl
## it seems the complxity of the model improves the RMSE until the model hits around 0.006 after which the 
### model becomes too complex and decreses the RMSE
plot(tree_mdl)
## we can see in the decsion tree model the ladder position and inside_50 numbers were a huge factor in deciding the data
rattle::fancyRpartPlot(tree_mdl$finalModel, sub = "")
## looking at the variable importance it seems that the ladder position and inside_50 are very important
## other scoring metrics from previous weeks being less important
## as we saw with the complexity plot the decsion tree improved after some level of complexity but including too many variables decresaed the RMSE
plot(varImp(tree_mdl), top = 20)

```

```{r}
set.seed(1)
rf_mdl <- train(pts ~ ., data = training_withDummies,
                method = 'rf',
                trControl = control_obj)

rf_mdl
plot(rf_mdl)
plot(varImp(rf_mdl), top = 20)
```

```{r}
set.seed(1)
knn_mdl <-  train(pts~ ., data = training, method = "knn",
                  preProc = c('center', 'scale'),
                  tuneGrid = data.frame(.k = 1:60),
                  trControl = control_obj)

knn_mdl

```

```{r}
resampls <- resamples(list(LM = lm_mdl,
                           TREE = tree_mdl,
                           RF = rf_mdl,
                           KNN = knn_mdl))
## displaying the model perfomance in order to select the best model
gridExtra::grid.arrange(bwplot(resampls, metric = 'RMSE'),
                        bwplot(resampls, metric = 'Rsquared'),
                        ncol = 2)

```

```{r}
## using the linear model to predcit the score_margin in the testing
testing <-  testing %>%
  mutate(predictions = predict(lm_mdl, newdata = testing))

## calculting the RMSE amd R squared of the linear model on the testing data
RMSE(pred = testing$predictions,
     obs = testing$pts)
R2(pred = testing$predictions,
   obs = testing$pts)

## The linear model returned an RMSE of ~36 and an R sqaured of ~13%
## which indicates a poor perceratge of the new data explained by the model 

## plotting the predictions against the actual score margin from the testing data
testing <- cbind(testing, testing_countries)

plot <- ggplot(testing, aes(predictions, pts, label = country)) +
  geom_point(colour = '#1111FF', alpha=0.7) +
  geom_abline(colour = "red", linetype = "dashed") 

plotly::ggplotly(plot)
```


```{r}
cols <- game_total %>% 
  select(mp:tov_p) %>% 
  colnames(.)

for (i in cols){
  print(gg_box_t_stage(i))
}

for (i in cols){
  print(gg_box_year(i))
}

for (i in cols){
  print(gg_point_pts(i))
}

game_total %>% 
  select(c(mp:tov_p, -results)) %>% 
  correlate() %>% 
  focus(pts) %>% 
  arrange(-pts)

game_total %>% 
  group_by(game_number) %>% 
  count()

```


```{r}
pts_predict <- game_total %>% 
  select(mp:tov_p)

fit <- lm(pts ~ ., pts_predict)
summary(fit)
std_res <- rstandard(fit)
points <- 1:length(std_res)

ggplot(NULL, aes(points, std_res)) +
  geom_point() +
  ylim(c(-4,4)) +
  geom_hline(yintercept = c(-3,3) , colour = "red", linetype = "dashed") + 
  labs(title = "Residual plot",
       x = "",
       y = "Residuals",
       caption = "Figure 3") +
  theme_bw()

car::durbinWatsonTest(fit)
res <- residuals(fit)
variables <- caret::varImp(fit, scale = TRUE) %>% arrange(-Overall) 

```

```{r}
pts_predict <- game_total %>% 
  select(mp:tov_p) %>% 
  mutate(results = if_else(results == "W",1,0))

fit <- lm(results ~ ., pts_predict)
summary(fit)
std_res <- rstandard(fit)
points <- 1:length(std_res)

ggplot(NULL, aes(points, std_res)) +
  geom_point() +
  ylim(c(-4,4)) +
  geom_hline(yintercept = c(-3,3) , colour = "red", linetype = "dashed") + 
  labs(title = "Residual plot",
       x = "",
       y = "Residuals",
       caption = "Figure 3") +
  theme_bw()

car::durbinWatsonTest(fit)
res <- residuals(fit)
variables <- caret::varImp(fit, scale = TRUE) %>% arrange(-Overall) 


```

```{r}

```

